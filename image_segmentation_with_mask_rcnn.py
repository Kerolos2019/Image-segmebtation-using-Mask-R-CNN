# -*- coding: utf-8 -*-
"""Image Segmentation with Mask RCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10ZTDgz4EP6HrgMVYifqQshmVqg8pm51h

# Computer Vision Masterclass - Image Segmentation with Mask R-CNN

## Downloading the repository
"""

!git clone https://github.com/matterport/Mask_RCNN

# Commented out IPython magic to ensure Python compatibility.
# %cd Mask_RCNN

pwd

!python setup.py install

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

pwd

"""## Importing the libraries"""

import os
import sys
import cv2
import numpy as np
import skimage.io
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import tensorflow as tf

tf.__version__

ROOT_DIR = os.path.abspath('./Mask_RCNN')
ROOT_DIR

sys.path

sys.path.append(ROOT_DIR)

sys.path

from mrcnn import utils
from mrcnn import visualize
import mrcnn.model as modellib

# https://cocodataset.org/#home
sys.path.append(os.path.join(ROOT_DIR, 'samples/coco/'))

sys.path

import coco

MODEL_DIR = os.path.join(ROOT_DIR, 'logs')
IMAGE_DIR = os.path.join(ROOT_DIR, 'images')

MODEL_DIR, IMAGE_DIR

"""## Loading the pre-trained neural network"""

COCO_MODEL_PATH = os.path.join(ROOT_DIR, 'mask_rcnn_coco.h5')

utils.download_trained_weights(COCO_MODEL_PATH)

class InferenceConfig(coco.CocoConfig):
  GPU_COUNT = 1
  IMAGES_PER_GPU = 1

config = InferenceConfig()

config.display()

MODEL_DIR

network = modellib.MaskRCNN(mode='inference', model_dir=MODEL_DIR, config=config)

!pip install h5py==2.10.0

network.load_weights(COCO_MODEL_PATH, by_name=True)

"""## Detecting objects """

class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
               'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']

len(class_names)

class_names[1], class_names.index('person')

image = skimage.io.imread('/content/Mask_RCNN/images/2516944023_d00345997d_z.jpg') # RGB

plt.imshow(image);

class_names[17], class_names[1], class_names[14]

results = network.detect([image], verbose=0)
results

r = results[0]

visualize.display_instances(image, r['rois'], r['masks'],
                            r['class_ids'], class_names, r['scores'])

"""## Segmentation in videos"""

from google.colab import drive
drive.mount('/content/drive')

capture = cv2.VideoCapture('/content/drive/MyDrive/cars.mp4')
connected, frame = capture.read()
connected

frame.shape

save_video = cv2.VideoWriter('/content/drive/MyDrive/cars_results.avi',
                             cv2.VideoWriter_fourcc(*'XVID'), 24, (frame.shape[1], frame.shape[0]))

!cp /content/drive/MyDrive/PyCharm/video_functions.py ./Mask_RCNN/mrcnn

from mrcnn import video_functions

colors = video_functions.random_colors(len(class_names), 55)
len(colors)

print(colors)

def show(img):
  fig = plt.gcf()
  fig.set_size_inches(16,10)
  plt.axis('off')
  plt.imshow(img)
  plt.show()

frame_show = 20
current_frame = 0

while (cv2.waitKey(1) < 0):
  connected, frame = capture.read()

  if not connected:
    break

  results = network.detect([frame], verbose=0)
  r = results[0]

  processed_frame = video_functions.display_instances(frame, r['rois'], r['masks'],
                                                      r['class_ids'], class_names, r['scores'], colors=colors)
  
  if current_frame <= frame_show:
    show(processed_frame)
    current_frame += 1
  
  save_video.write(cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB))
save_video.release()